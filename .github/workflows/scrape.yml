name: Scrape Wix Snapshot
on:
  workflow_dispatch: {}

jobs:
  scrape:
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/playwright:v1.47.0-jammy
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Show workspace (debug)
        run: |
          echo "PWD=$(pwd)"
          ls -la
          echo "Branch:"
          git branch --show-current || true

      - name: Ensure Node project exists + write script
        run: |
          if [ ! -f package.json ]; then
            echo "No package.json -> bootstrap"
            npm init -y
            npm pkg set type=module
          fi
          mkdir -p scripts
          cat > scripts/scrape.mjs <<'EOF'
          import fs from "fs/promises";
          import path from "path";
          import axios from "axios";
          import { XMLParser } from "fast-xml-parser";
          import { chromium } from "playwright";

          const baseUrl = process.argv[2] || "https://www.pozza-maud-psy-angers.com/";
          const OUT_DIR = path.resolve("out");

          function urlToFilePath(urlStr) {
            const u = new URL(urlStr);
            let p = u.pathname;
            if (!p || p === "/") p = "/index";
            if (p.endsWith("/")) p = p + "index";
            p = p.replace(/\/+/g, "/").replace(/[^a-zA-Z0-9/_-]/g, "-");
            return path.join(OUT_DIR, p) + ".html";
          }

          async function getUrlsFromSitemap() {
            try {
              const { data } = await axios.get(new URL("/sitemap.xml", baseUrl).toString(), { timeout: 15000 });
              const parser = new XMLParser({ ignoreAttributes: false });
              const xml = parser.parse(data);
              const nodes = xml.urlset?.url || [];
              const urls = (Array.isArray(nodes) ? nodes : [nodes]).map(u => u.loc).filter(Boolean);
              if (!urls.includes(baseUrl)) urls.unshift(baseUrl);
              return urls;
            } catch {
              console.warn("Pas de sitemap.xml — on capture la home.");
              return [baseUrl];
            }
          }

          async function autoScroll(page) {
            await page.evaluate(async () => {
              await new Promise(resolve => {
                let total = 0;
                const dist = 600;
                const timer = setInterval(() => {
                  const sh = document.body.scrollHeight;
                  window.scrollBy(0, dist);
                  total += dist;
                  if (total >= sh - window.innerHeight) { clearInterval(timer); resolve(); }
                }, 200);
              });
            });
          }

          (async () => {
            const urls = await getUrlsFromSitemap();
            console.log(`Captures: ${urls.length} pages`);
            const browser = await chromium.launch({ headless: true });
            try {
              for (const url of urls) {
                console.log("→", url);
                const page = await browser.newPage();
                await page.goto(url, { waitUntil: "networkidle" });
                await autoScroll(page);

                // liens internes => relatifs
                await page.evaluate((base) => {
                  for (const a of document.querySelectorAll("a[href]")) {
                    try {
                      const u = new URL(a.getAttribute("href"), base);
                      if (u.origin === location.origin) a.setAttribute("href", u.pathname + u.search + u.hash);
                    } catch {}
                  }
                }, baseUrl);

                const html = await page.content();
                const filePath = urlToFilePath(url);
                await fs.mkdir(path.dirname(filePath), { recursive: true });
                await fs.writeFile(filePath, html, "utf8");
                await page.close();
              }
            } finally {
              await browser.close();
            }
            console.log(`✅ HTML rendu sauvegardé dans: ${OUT_DIR}`);
          })();
          EOF

      - name: Install deps
        run: |
          npm i axios fast-xml-parser playwright

      - name: Run scrape
        run: node scripts/scrape.mjs "https://www.pozza-maud-psy-angers.com/"

      - name: Upload artifact (download snapshot)
        uses: actions/upload-artifact@v4
        with:
          name: wix-snapshot
          path: out/

      - name: Commit snapshot into repo
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: snapshot Wix (Playwright)"
          file_pattern: out/**